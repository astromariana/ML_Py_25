{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad7a8eef-20b8-4a4e-ab4f-48b0b6913ede",
   "metadata": {},
   "source": [
    "![imagenes](logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e981639-6665-4367-880b-041909217a77",
   "metadata": {},
   "source": [
    "# Tratamiento de valores faltantes\n",
    "\n",
    "Cuando trabajamos con datos reales, tarde o temprano aparecen huecos: celdas en blanco, registros incompletos o valores dañados. En Python se representan con ``NaN``, en R con ``NA``, y en otros entornos con símbolos parecidos. Pero todos significan lo mismo: información que no está disponible.\n",
    "\n",
    "Estos huecos pueden tener muchas causas. Tal vez un encuestado no respondió cierta pregunta, quizá un sensor falló en el momento de la medición, o simplemente un sistema de captura no registró el valor.\n",
    "\n",
    "Imagina a un alumno que presenta un examen y deja varias preguntas sin contestar. El profesor puede tomar distintas decisiones: ignorar esas preguntas, calificarlas con cero o tratar de deducir cuál habría sido la respuesta correcta a partir del resto del examen. En un modelo de Machine Learning ocurre algo similar: debemos decidir qué hacer con la información que falta.\n",
    "\n",
    "## Estrategias principales\n",
    "\n",
    "Existen varias formas de tratar valores faltantes. Ninguna es universalmente mejor que otra: todo depende del contexto, de la cantidad de huecos y de la importancia de la columna en cuestión.\n",
    "\n",
    "### Imputación simple\n",
    "\n",
    "Otra estrategia es rellenar los huecos con valores representativos. Podemos usar la media, la mediana o la moda de la columna. También es posible asignar un número fijo, como cero o “desconocido”.\n",
    "\n",
    "En Python, ``SimpleImputer`` de scikit-learn hace este trabajo de forma automática. Aquí el profesor del examen estaría “rellenando” las preguntas en blanco con la respuesta más común de los alumnos. No es perfecto, pero evita perder información.\n",
    "\n",
    "### Imputación avanzada\n",
    "\n",
    "Cuando el problema es más complejo, se pueden usar técnicas más sofisticadas. El **KNN Imputer** busca los registros más parecidos al que tiene el hueco y utiliza sus valores para completarlo. El **Iterative Imputer** construye modelos internos que predicen los valores faltantes a partir de las demás variables.\n",
    "\n",
    "En nuestra analogía, Rocky entrena con sparrings que se parecen a su rival, para compensar los movimientos que no había practicado antes. Así llena sus vacíos con experiencias cercanas.\n",
    "\n",
    "### Variables indicadoras\n",
    "\n",
    "En ocasiones conviene crear una columna adicional que indique si un valor fue imputado o no. De esta forma el modelo puede aprender que la ausencia de datos en sí misma contiene información. En la práctica, esto es como que el profesor deje una marca en el examen para recordar que cierta respuesta fue rellenada artificialmente.\n",
    "\n",
    "## La fuga de datos\n",
    "\n",
    "Al igual que en la codificación de variables categóricas, aquí también debemos cuidar la fuga de datos. Nunca se deben calcular promedios o medianas usando todo el dataset antes de separar en entrenamiento y prueba.\n",
    "\n",
    "Si lo hacemos, el modelo ya estaría “viendo” información del conjunto de prueba durante el entrenamiento. El paralelo en el examen sería que el niño recibe de antemano las respuestas del examen final disfrazadas en el cuestionario de práctica. El resultado será una calificación irrealmente alta.\n",
    "\n",
    "Por eso, la regla de oro es:\n",
    "1. Dividir primero en entrenamiento y prueba.\n",
    "2. Ajustar (``fit``) el imputador solo con el entrenamiento.\n",
    "3. Aplicar (``transform``) esa misma estrategia en entrenamiento y prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71cb20a-5bc7-4dc8-8ad7-f5a3a32c249a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "datos = pd.read_csv(\"datos_con_faltantes.csv\")\n",
    "datos.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fd8091-b528-4af7-963e-a1618b7c10b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Radiografía de faltantes (conteo y porcentaje)\n",
    "\n",
    "faltantes = datos.isna().sum().sort_values(ascending=False)\n",
    "porcentaje = (datos.isna().mean()*100).round(2).sort_values(ascending=False)\n",
    "resumen_faltantes = pd.DataFrame({\"faltantes\": faltantes, \"porcentaje_%\": porcentaje})\n",
    "print(\"\\nResumen de faltantes por columna:\\n\")\n",
    "print(resumen_faltantes, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493b0292-899b-4917-b6e8-59a103964e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir columnas cuantitativas\n",
    "\n",
    "cols_quant_media   = [\"ingreso\"]           # imputar con MEDIA\n",
    "cols_quant_mediana = [\"gasto\", \"edad\"]     # imputar con MEDIANA\n",
    "cols_passthrough = [\"completo\"]\n",
    "\n",
    "'''\n",
    "Explicación del ColumnTransformer\n",
    "\n",
    "transformers = [\n",
    "  (\"quant_media\",\n",
    "     SimpleImputer(strategy=\"mean\", add_indicator=True),\n",
    "     cols_quant_media),\n",
    "\n",
    "  (\"quant_mediana\",\n",
    "     SimpleImputer(strategy=\"median\", add_indicator=True),\n",
    "     cols_quant_mediana),\n",
    "\n",
    "  (\"passthrough\",\n",
    "     \"passthrough\",\n",
    "     [todas las demás columnas])\n",
    "]\n",
    "\n",
    "- MEDIA para columnas donde la distribución es aproximadamente simétrica.\n",
    "- MEDIANA para columnas sesgadas o con outliers.\n",
    "- add_indicator=True añade banderas de imputación por columna numérica.\n",
    "- remainder=\"passthrough\" conserva todo lo no listado (categóricas, 'completo', etc.) tal cual.\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "preprocesador = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"quant_media\",\n",
    "         SimpleImputer(strategy=\"mean\", add_indicator=False),\n",
    "         cols_quant_media),\n",
    "\n",
    "        (\"quant_mediana\",\n",
    "         SimpleImputer(strategy=\"median\", add_indicator=False),\n",
    "         cols_quant_mediana),\n",
    "\n",
    "        (\"passthrough\",\n",
    "         \"passthrough\",\n",
    "         cols_passthrough),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    "    verbose_feature_names_out=False\n",
    ")\n",
    "\n",
    "# \n",
    "# Ajustar y transformar\n",
    "# preprocesador.fit(datos)\n",
    "\n",
    "X_imp    = preprocesador.transform(datos)\n",
    "cols_out = preprocesador.get_feature_names_out()\n",
    "\n",
    "df_imputado = pd.DataFrame(X_imp, columns=cols_out, index=datos.index)\n",
    "df_imputado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2926fa7-f544-4d24-8ed0-15e6773c9dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "faltantes = df_imputado.isna().sum().sort_values(ascending=False)\n",
    "porcentaje = (df_imputado.isna().mean()*100).round(2).sort_values(ascending=False)\n",
    "resumen_faltantes = pd.DataFrame({\"faltantes\": faltantes, \"porcentaje_%\": porcentaje})\n",
    "print(\"\\nResumen de faltantes por columna:\\n\")\n",
    "print(resumen_faltantes, \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
